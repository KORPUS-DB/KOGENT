{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install and import modules**"
      ],
      "metadata": {
        "id": "3SCcBjkzF_NF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9s7v3E9F0MX"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "import os\n",
        "from openai import OpenAI # for access to GPT API\n",
        "import pandas as pd\n",
        "from tqdm import tqdm # for progress check"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Few (18)-shot Prompt**"
      ],
      "metadata": {
        "id": "riCvSbEPGPCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# System instruction and Hyperparameter (few-shot)\n",
        "PROFILE_few_shot =\"\"\"# 정의\n",
        "- (본 연구의) 성인지 감수성 정의: 성 차별 및 성불평등적 요소를 부인한다거나, 자신과 다른 성을 가진 사람들과의 차이에 대한 다양성을 부정하거나, 특정 성별의 우위 혹은 열위를 주장하거나 이를 전제하는 차별적 발언을 하거나, 과거의 가부장적이고 차별적 사회구조를 인정하고 옹호하는 것\n",
        "\n",
        "# H/L/I 예시\n",
        "문장: 기존 연구는 주로 아이의 성장에 미치는 어머니의 영향에 초점이 맞추어져 있지 아버지의 역할은 연구가 되지 않는데, 그만큼 자녀 양육은 여성의 역할이라는 인식이 우리 사회에 오랫동안 박혀 있기 때문입니다. 그러니까 자녀 교육ㆍ양육에 대한 인식 개선이 필요하다는 말씀을 드리고 있는 것입니다.\n",
        "판단: H\n",
        "\n",
        "문장: 새로운 가족정책의 패러다임은 민주적이고 평등한 가족관계를 정립하고 가족에 대한 국가의 보호와 지원을 확대하는 방향이어야 합니다. 과거의 가부장․권위주의적인 가족문화를 지양하고 민주적이고 평등한 가족관계와 문화를 정착시킴으로써 가정폭력, 가족해체 등 가족의 안정성을 위협하는 근본요인을 해소할 수 있도록 하기 위함입니다.\n",
        "판단: H\n",
        "\n",
        "문장: 다만 제가 정치를 하는 동안 또 사회운동을 하는 동안 사실 가계를 저희 집사람이 꾸려왔기 때문에 저런 여러 가지 흠결은 사실은 제가 져야 될 몫입니다.\n",
        "판단: L\n",
        "\n",
        "문장: 그랬더니 이쁜 사람만 골라다 놓는가 보다 이 생각도 들고, 아무튼 제가 여성문제에 관해서 집에 가서는 아닌데 밖에 나오면 일단 적극적인 여성 옹호론자가 확실합니다.\n",
        "판단: L\n",
        "\n",
        "문장: 임수경 의원안은 기존 '아동'에서 보호 범위를 넓혀 '청소년'을 포함시키려는 것으로 다문화가족 실태조사의 대상을 확대하고 아동과 청소년에게 보육·교육 지원을 할 수 있도록 함으로써 다문화가족 지원을 강화하려는 것입니다. 검토의견입니다.\n",
        "판단: I\n",
        "\n",
        "문장: 예, 파악해 가지고 대안을 마련해서 보고하도록 하겠습니다. 이것은 내가 잠깐만 얘기하고 지나갔으면 좋겠는데요. 이게 지금 우리나라 50대·60대의 평생 지출 구조가 외국하고 다릅니다. 외국은 자식들이 18살이나 20살 정도가 되면 독립을 해 가지고 부모가 자식들을 부양할 목돈이 필요하지 않은데 우리나라는 아이들이 부모에 대한 의존도가 한 30살까지 가게 되는 일이 많고 또 그 나이에 결혼을 하는 일도 많고 하기 때문에 실제로 50대 후반에서 60대 초반 사이에 목돈 쓸 일이 굉장히 많아요. 그래서 지출 구조가 굉장히 차이가 있어요. 그런데 지금 퇴직은 50세·55세 이 정도에 하고 연금수급을 받을 때까지 간격이 꽤 벌어지고 최근에는 국민연금도 수급연령을 연장하고 공무원연금도 연장하자는 얘기가 나오고 있는데, 그러면 사실 50대 후반에서 60대 넘어서 연금수급을 받을 때까지 그 간격 사이에 상당한 문제가 있어요. 제도설계상에 기본적으로 문제가 있어요. 그러니까 조기수급을 받아서 노후소득이 부족해진다는 것만을 탓할 수는 없어요, 지금 상황이. 그러니까 대안을 내시도록 김현숙 위원이 요구를 하시니까 대안을 마련해 보시는데, 내 생각에는 이거를 무조건 나쁜 제도다 이렇게 치부할 수는 없어요, 지금 현재 상황이.\n",
        "판단: I\n",
        "\n",
        "문장: 지금 존경하는 김옥이 위원님께서 지적하신 것 같이 우리나라 고위공직자 비율이 굉장히 낮습니다. 그렇지만 지금 이제 새로 진입하는 여성들은 고시나 이런 것을 통해서 진입하는 여성은 많습니다. 그렇지만 위에는 지금 훈련되고 키워진 여성이 적기 때문에 인력풀 자체가 적고요, 또 보직이나 승진에 있어서 그동안 눈에 보이지 않는 차별이 또 작용을 했기 때문에 지금 현재 이런 현상이 일어나고 있다고 생각을 합니다. 그래서 앞으로 여성 고위공직자 비율을 지표관리를 해서 어느 수준 이상 달성하도록 구체적인 목표 설정을 하고 그것을 점검하면서 제고를 하기 위해 노력을 하겠고요, 또 개방형이나 계약직 이렇게 특채 형식의 공무원 채용 시 여성이 많이 들어갈 수 있도록 최선의 노력을 다하겠습니다.\n",
        "판단: H\n",
        "\n",
        "문장: 페이 미투는 여성이 임금에서 차별을 받고 있다는 내용입니다. 그래서 남녀 간의 임금격차를 해소해서 경제적인 성평등을 이뤄야 된다 하는 내용인데요. 우리나라는 사실 아시다시피 여성 경제활동률이 굉장히 낮습니다. 그뿐 아니라 남녀의 임금격차가 OECD 국가 중에서 월등하게 1위입니다. 그야말로 월등하게 1위입니다. 그래서 이것에 대한 것을, 다른 나라들은 우리나라보다 훨씬 덜한 데도 이것을 개선하기 위한 노력을 굉장히 많이 하고 있거든요. 영국이나 아이슬란드나 독일이나 이런 노력들을 많이 하고 있는데 우리나라는 아직까지 실제적인 임금격차가 사실은 남자의 임금의 63% 정도밖에 못 받고 있는데 이를 개선하기 위한 노력이 많지가 않거든요. 이것을 어떤 식으로 개선할 수 있다고 생각을 하십니까?\n",
        "판단: H\n",
        "\n",
        "문장: 여성이라는 이유로 민간기업 활동과 여성 지위 향상을 연결시키려는 이런 것들은 자칫 포퓰리즘 정책이다 또 국가가 기업을 통제하려는 것이다, 기업의 자율적인 활동을 위축시키는 것이다 이런 위험성을 가져올 수 있는데 장관님, 어떻게 생각하십니까?\n",
        "판단: L\n",
        "\n",
        "문장: 여가부는 다 알다시피 지난 2001년에 김대중 정부에서 여성부로 신설됐습니다. 당시 명칭이 미니스트리 오브 젠더 이퀄리티(Ministry of Gender Equality)라고 해서 젠더 이퀄리티, 즉 양성평등을 내세우고 출범을 했지요. 그러나 여가부의 과도한 여성정책으로 인해서 정작 양성평등보다 남녀 갈등만 심화되고 있는 상황입니다. 나아가 여가부가 남성 혐오와 여성 우월주의를 조장한다는 비판까지 받고 있는 실정입니다.\n",
        "판단: L\n",
        "\n",
        "문장: 우선 국민취업지원제도가 완전히 새로 탄생하는 제도가 아니고요. 현재 있는 취업성공패키지 사업과 그다음에 청년구직활동지원금을 결합해서 그것을 체계화시키는 겁니다. 그렇기 때문에 별도 법률을 제정하면 거기에서 체계적으로 할 수 있다 하는 거고요. 이 두 가지 사업이 이미 현재 고용정책 기본법 제26조 취업취약계층의 고용촉진 지원에 관한 것에 근거해 가지고 시행을 하고 있는 상태입니다. 그렇기 때문에 이것 두 개를 결합한 새로운 사업도 이 법에 근거해서 할 수 있다고 보고 있는 거고요. 그래서 법률의 제정을 전제로 하지는 않고 있다고 보는 거고 법률이 제정이 되면 훨씬 더 체계적으로 할 수 있다라고 생각하고 있습니다. 그래서 저는...... 이게 계속사업입니다, 신규사업도 아니고.\n",
        "판단: I\n",
        "\n",
        "문장: 오늘 심사할 안건들은 금융회사의 지배구조 개선을 비롯하여 금산분리 강화, 대기업집단의 일감몰아주기와 순환출자 규제, 대리점 거래의 공정화 등 사회적으로 이슈가 되고 있는 경제민주화와 관련된 중요 법안들로서 국민들과 언론에서 많은 관심을 갖고 있는 법안들입니다. 이들 법안에 대하여는 그동안 수차례에 걸친 소위원회 심사 과정에서 많은 논의가 있었습니다.\n",
        "판단: I\n",
        "\n",
        "문장: 그런데 저는 개인적으로 동성애라는 것은 무슨 찬성, 반대나 옳고 그름의 문제가 아니라 다수자인 이성애와 다른 성적 지향을 가리킨다고 봅니다. 그래서 일종의 소수자인 거지요. 마치 위원님 아시다시피 왼손잡이가 대략 10% 미만인데 어찌 보면 그와 유사하지 않느냐 싶어서...... 그리고 국가인권위원회법 2조에 보면 성적 지향을 차별하면 안 된다는, 평등권 침해로 보고 있습니다. 그렇게 보면 또 최근에 미국 연방대법원이나 세계 각국에서 동성애를 허용하는 쪽으로 나가고 있고요. 그래서 그런 것들에 대해서 우리 사회가 진지하게 모색할 때가 됐다 이렇게 보고 있습니다.\n",
        "판단: H\n",
        "\n",
        "문장: 기본적으로 저는 동성애는 차별되거나 배제되어서는 안 되는 거라고 생각을 합니다. 국가인권위원회법에서도 성적 지향, 이것을 가지고 차별해서는 안 된다는 것이 돼 있고 국제사회에서도 그렇습니다. 이 입장을 같이하고 있습니다.\n",
        "판단: H\n",
        "\n",
        "문장: 동성애에 대해서 어제 김선수 후보자도 그렇고 지금 노정희 후보자도 그러시는데 동성애 소수자 보호, 소수자로서 인권이 차별을 받아서는 안 된다 이렇게 주장을 하는데요. 절대다수의 국민들은 동성애에 대해서 ‘동성애가 허용되는 대한민국은 불행한 국가다’, 행복추구권이 침해된다고 절대다수의 국민들이 외치고 있어요. 그 절대다수의 국민들은 왜 외면하지요? 그분들의 인권은 왜 보호되지 않나요?\n",
        "판단: L\n",
        "\n",
        "문장: 본 의원의 생각과 아주 정확하게 일치하는 견해신데요, 폐쇄된 군대 내에서 동성애가 허용된다면 이것은 자연발생적으로 또 자유로운 선택에 의해서 동성애가 이루어지는 것이 절대 아닙니다. 그것은 고참이 신참 부하에 대한 성추행을 하는 환경이 조성된다든지 또 군대 내 기강 문란으로 이어져서 저는 굉장히 큰 혼란이 빚어질 수 있다 이렇게 생각을 합니다. 또 에이즈 감염도 우려가 됩니다. 그렇지요?\n",
        "판단: L\n",
        "\n",
        "문장: 사실은 그게 참 불합리해요. 앞에 해야지요. 지금 1시간으로 시간을 정해 놓았잖아요. 1시간 하고...... 5분자유발언은 당일 처리할 안건하고는 별개로 전반적인 것에 대해서...... 그것을 아는데요. 어찌 됐든 그것을 앞에 해야지 사람도 거의 없는 데 가서 하면......\n",
        "판단: I\n",
        "\n",
        "문장: 답변하십시오. 북한인권재단 사무실을 정리하게 된 것은 여러 차례 말씀드렸지만 계속 비용이 부담됐기 때문에 문정인 특보의 발언 이것하고는 전혀 무관하고요. 다만 계속해서 말씀드리지만 저희가 인권 문제에 소홀하다는 지적을 계속 주셨습니다. 하여튼 그런 지적에 유념해서 인권정책도 인권재단 출범 등을 포함해서 북한 인권 문제의 증진을 위해서 계속 더 노력을 하겠습니다.\n",
        "판단: I\n",
        "\n",
        "\n",
        "# 지시\n",
        "- 위 예시를 참고하여 주어진 문장의 성인지 감수성이 높으면 H, 성인지 감수성이 낮으면 L, 성인지 감수성과 관련이 없으면 I로 판단하라.\n",
        "- 판단에는 H, L, I 중 하나만 들어가야 한다.\n",
        "- 판단에 H, L, I 외에 \"판단은\", \"판단:\" 등과 같은 다른 말이 들어가서는 안 된다.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Kd3xfDVbGXYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero-shot prompt**"
      ],
      "metadata": {
        "id": "yVDsueZeGYd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROFILE_zero_shot =\"\"\"# 정의\n",
        "- (본 연구의) 성인지 감수성 정의: 성 차별 및 성불평등적 요소를 부인한다거나, 자신과 다른 성을 가진 사람들과의 차이에 대한 다양성을 부정하거나, 특정 성별의 우위 혹은 열위를 주장하거나 이를 전제하는 차별적 발언을 하거나, 과거의 가부장적이고 차별적 사회구조를 인정하고 옹호하는 것\n",
        "\n",
        "# 지시\n",
        "- 주어진 문장의 성인지 감수성이 높으면 H, 성인지 감수성이 낮으면 L, 성인지 감수성과 관련이 없으면 I로 판단하라.\n",
        "- 판단에는 H, L, I 중 하나만 들어가야 한다.\n",
        "- 판단에 H, L, I 외에 \"판단은\", \"판단:\" 등과 같은 다른 말이 들어가서는 안 된다.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Hu1BJVrrGcwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "NkMNzOFfGp9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS = 2\n",
        "TEMPERATURE = 0.0"
      ],
      "metadata": {
        "id": "nKsQ085SG1Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accessing the OpenAI API**"
      ],
      "metadata": {
        "id": "ukEWqSGJG1y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"\" # Insert your API key here\n",
        "def run_openai_gpt(profile, query, version):\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": profile,\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": query,\n",
        "            }\n",
        "        ],\n",
        "        model=version,\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        temperature=TEMPERATURE\n",
        "    )\n",
        "\n",
        "    return chat_completion.choices[0].message"
      ],
      "metadata": {
        "id": "AtzrxrIWG6QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Dataframe**\n",
        "\n",
        "Multiple excel files were combined for the original experiment; this code is redesigned for compatibility with our dataset (available at Figshare)"
      ],
      "metadata": {
        "id": "Hwt455mcHEYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_utterances = pd.read_csv(\"utterances.csv\")"
      ],
      "metadata": {
        "id": "LFcTE_-yIs_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run Test: Few-shot**"
      ],
      "metadata": {
        "id": "WODcIxedI9_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_gpt_41_few_shot = [] # assign a different name for experiments with another model (ex. gpt-4o)\n",
        "\n",
        "for sentence in tqdm(df_utterances[\"utterances\"]):\n",
        "    query = f\"문장: {sentence}\\n판단:\"\n",
        "    response = run_openai_gpt(profile=PROFILE_few_shot, query=query, version=\"gpt-4.1-2025-04-14\") # provide the snapshot of your GPT model of choice\n",
        "    print(response.content)\n",
        "    pred_gpt_41_few_shot.append(response.content)\n",
        "\n",
        "df_utterances['pred_few'] = pred_gpt_41_few_shot # add a new column containing predictions from the few-shot experiment"
      ],
      "metadata": {
        "id": "ziXRzpE2I9iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run Test: Zero-shot**"
      ],
      "metadata": {
        "id": "nyCLfZFEKNiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_gpt_41_zero_shot = []  # assign a different name for experiments with another model (ex. gpt-4o)\n",
        "\n",
        "for sentence in tqdm(df_utterances[\"utterances\"]):\n",
        "    query = f\"문장: {sentence}\\n판단:\"\n",
        "    response = run_openai_gpt(profile=PROFILE_zero_shot, query=query, version=\"gpt-4.1-2025-04-14\") # provide the snapshot of your GPT model of choice\n",
        "    print(response.content)\n",
        "    pred_gpt_41_zero_shot.append(response.content)\n",
        "\n",
        "df_utterances['pred_zero'] = pred_gpt_41_zero_shot # add a new column containing predictions from the zero-shot experiment\n",
        "df_utterances.to_csv('utterances_with_predictions.csv', index=False) # once both experiments are complete, save the new prediction columns to a new csv file (to prevent override)"
      ],
      "metadata": {
        "id": "Ayij3fg3Ke1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization Setup**"
      ],
      "metadata": {
        "id": "_-UpwkxKL8mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "CaYxHWTbL-dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix: 18-shot GPT-4.1**"
      ],
      "metadata": {
        "id": "jUFv8nitOFIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class labels\n",
        "labels = [\"H\", \"I\", \"L\"]\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm1 = confusion_matrix(df_utterances[\"gender_sensitivity\"], df_utterances[\"pred_few\"], labels=labels) # the \"gender_sensitivity\" column contains groundtruth labels for each utterance\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels,annot_kws={\"size\": 20})\n",
        "\n",
        "# Axis labels and title\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"Groundtruth Label\")\n",
        "plt.title(\"Confusion Matrix (18-shot GPT-4.1 vs Ground Truth)\") # adjust title for different models\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification metrics and overall accuracy\n",
        "print(\"Classification Report (18-shot GPT-4.1 vs Ground Truth):\\n\")\n",
        "print(classification_report(df_utterances[\"gender_sensitivity\"], df_utterances[\"pred_few\"], labels=labels))\n",
        "accuracy = accuracy_score(df_utterances[\"gender_sensitivity\"], df_utterances[\"pred_few\"])\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "Gak_2bx2OJSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix: Zero-shot GPT-4.1**"
      ],
      "metadata": {
        "id": "C8JYZ7SqPDok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class labels\n",
        "labels = [\"H\", \"I\", \"L\"]\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm2 = confusion_matrix(df_utterances[\"gender_sensitivity\"], df_utterances[\"pred_zero\"], labels=labels) # the \"gender_sensitivity\" column contains groundtruth labels for each utterance\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels,annot_kws={\"size\": 20})\n",
        "\n",
        "# Axis labels and title\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"Groundtruth Label\")\n",
        "plt.title(\"Confusion Matrix (0-shot GPT-4.1 vs Ground Truth)\") # adjust title for different models\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification metrics and overall accuracy\n",
        "print(\"Classification Report (0-shot GPT-4.1 vs Ground Truth):\\n\")\n",
        "print(classification_report(df_utterances[\"gender_sensitivity\"], df_utterances[\"pred_zero\"], labels=labels))\n",
        "accuracy = accuracy_score(df_utterances[\"gender_sensitivity\"], df_utterances[\"pred_zero\"])\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "_E8w0lAPPI7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}